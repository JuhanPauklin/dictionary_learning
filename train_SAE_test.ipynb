{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8598325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 50_000_000 # numbrid p√§rit dictionary_learning_demo/demo_config.py-st\n",
    "sae_batch_size = 2048\n",
    "steps = int(num_tokens / sae_batch_size) # Total number of batches to train\n",
    "log_steps = 100  # Log the training on wandb or print to console every log_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fec79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainer': <class 'dictionary_learning.trainers.standard.StandardTrainer'>, 'dict_class': <class 'dictionary_learning.dictionary.AutoEncoder'>, 'activation_dim': 512, 'dict_size': 8192, 'lr': 0.001, 'device': 'cuda:0'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StandardTrainer.__init__() missing 3 required positional arguments: 'steps', 'layer', and 'lm_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     34\u001b[0m trainer_cfg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m: StandardTrainer,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict_class\u001b[39m\u001b[38;5;124m\"\u001b[39m: AutoEncoder,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: device,\n\u001b[1;32m     41\u001b[0m }\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# train the sparse autoencoder (SAE)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m ae \u001b[38;5;241m=\u001b[39m \u001b[43mtrainSAE\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# you could also use another (i.e. pytorch dataloader) here instead of buffer\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrainer_cfg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dictionary_learning/dictionary_learning/training.py:150\u001b[0m, in \u001b[0;36mtrainSAE\u001b[0;34m(data, trainer_configs, steps, use_wandb, wandb_entity, wandb_project, save_steps, save_dir, log_steps, activations_split_by_head, transcoder, run_cfg, normalize_activations, verbose, device, autocast_dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m     trainer_class \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 150\u001b[0m     trainers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrainer_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    152\u001b[0m wandb_processes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    153\u001b[0m log_queues \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: StandardTrainer.__init__() missing 3 required positional arguments: 'steps', 'layer', and 'lm_name'"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "from dictionary_learning import ActivationBuffer, AutoEncoder\n",
    "from dictionary_learning.trainers import StandardTrainer\n",
    "from dictionary_learning.training import trainSAE\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model_name = \"EleutherAI/pythia-70m-deduped\" # can be any Huggingface model\n",
    "\n",
    "model = LanguageModel(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    ")\n",
    "submodule = model.gpt_neox.layers[1].mlp # layer 1 MLP\n",
    "activation_dim = 512 # output dimension of the MLP\n",
    "dictionary_size = 16 * activation_dim\n",
    "\n",
    "# data must be an iterator that outputs strings\n",
    "data = iter(\n",
    "    [\n",
    "        \"This is some example data\",\n",
    "        \"In real life, for training a dictionary\",\n",
    "        \"you would need much more data than this\",\n",
    "    ]\n",
    ")\n",
    "buffer = ActivationBuffer(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    submodule=submodule,\n",
    "    d_submodule=activation_dim, # output dimension of the model component\n",
    "    n_ctxs=3e4,  # you can set this higher or lower dependong on your available memory\n",
    "    device=device,\n",
    ")  # buffer will yield batches of tensors of dimension = submodule's output dimension\n",
    "\n",
    "trainer_cfg = {\n",
    "    \"trainer\": StandardTrainer,\n",
    "    \"dict_class\": AutoEncoder,\n",
    "    \"activation_dim\": activation_dim,\n",
    "    \"dict_size\": dictionary_size,\n",
    "    \"lr\": 1e-3,\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "# train the sparse autoencoder (SAE)\n",
    "ae = trainSAE(\n",
    "    data=buffer,  # you could also use another (i.e. pytorch dataloader) here instead of buffer\n",
    "    trainer_configs=[trainer_cfg],\n",
    "    steps=steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26433100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning import AutoEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1789a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load autoencoder\n",
    "#ae = AutoEncoder.from_pretrained(\"/gpfs/helios/home/jpauklin/dictionary_learning/saes/trainer_0/ae.pt\") # to is rquired to load to GPU\n",
    "\n",
    "\n",
    "ae = AutoEncoder.from_pretrained(\"/gpfs/helios/home/jpauklin/dictionary_learning/dictionaries/pythia-70m-deduped/mlp_out_layer5/10_32768/ae.pt\")\n",
    "\n",
    "\n",
    "# get NN activations using your preferred method: hooks, transformer_lens, nnsight, etc. ...\n",
    "# for now we'll just use random activations\n",
    "activations = torch.randn(64, 512) # 768 estMed\n",
    "features = ae.encode(activations) # get features from activations\n",
    "reconstructed_activations = ae.decode(features)\n",
    "\n",
    "# you can also just get the reconstruction ...\n",
    "reconstructed_activations = ae(activations)\n",
    "# ... or get the features and reconstruction at the same time\n",
    "reconstructed_activations, features = ae(activations, output_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7764b30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6472,  1.5410, -0.9106,  ..., -1.5017,  1.5074,  0.3728],\n",
       "        [ 0.1759, -0.9854, -1.1953,  ..., -0.3835,  0.5757, -0.0051],\n",
       "        [-2.6950,  0.8102,  0.6362,  ...,  0.3335,  0.2446,  1.2338],\n",
       "        ...,\n",
       "        [-1.5096,  1.6440,  1.2469,  ...,  0.1677, -0.6865, -0.1040],\n",
       "        [-0.0327,  0.3279, -0.9597,  ...,  0.9221,  1.0353,  0.3163],\n",
       "        [ 0.9611, -0.2309,  0.9678,  ..., -0.1980,  0.9035, -1.1735]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed8108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8360e+00, -9.3310e+00, -1.3342e+01,  ..., -1.0414e+01,\n",
       "          1.0899e+01, -4.4748e+00],\n",
       "        [-1.3727e+01, -9.9600e+00, -1.5925e+01,  ..., -9.7325e+00,\n",
       "          4.5918e+00, -6.0350e+00],\n",
       "        [-1.6353e+01, -6.7410e+00, -4.2032e+00,  ..., -2.3968e-01,\n",
       "          1.3756e+00,  1.1615e+00],\n",
       "        ...,\n",
       "        [-1.6605e+00,  2.3595e-01,  2.0186e-03,  ..., -1.1771e+00,\n",
       "         -4.9485e-01, -3.6054e-01],\n",
       "        [-5.3005e+00, -4.4510e+00, -5.8403e+00,  ..., -1.6042e+00,\n",
       "          5.6609e+00, -1.0288e+00],\n",
       "        [-3.3809e+00, -5.3261e-01,  4.4034e-01,  ..., -3.2447e+00,\n",
       "          3.1148e+00, -2.6056e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_activations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
